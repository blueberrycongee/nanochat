"""
Analyze generated safety training data for nanochat.

This script validates and reports statistics on the safety conversations
generated by dev/gen_safety_data.py. It verifies data integrity, format,
and provides insight into the generated dataset composition.

Usage:
    python dev/analyze_safety_data.py

Example output:
    Total conversations: 500+
    Total messages: 2000+
    Conversation turns: 4 (all conversations)
    File size: ~2MB
"""

import json
import os
from collections import Counter

from nanochat.common import get_base_dir


def analyze_safety_data(file_path=None):
    """
    Analyze safety conversations data.
    
    Args:
        file_path: Path to safety_conversations.jsonl. If None, uses default cache location.
        
    Returns:
        dict: Statistics about the dataset
    """
    
    # Determine file path
    if file_path is None:
        file_path = os.path.join(get_base_dir(), "safety_conversations.jsonl")
    
    # Check if file exists
    if not os.path.exists(file_path):
        print(f"Error: Safety data file not found at {file_path}")
        print(f"Please run: python dev/gen_safety_data.py")
        return None
    
    # Read and analyze the data
    conversations = []
    total_messages = 0
    total_chars = 0
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    data = json.loads(line)
                    conversations.append(data)
                    total_messages += len(data)
                    total_chars += sum(len(msg.get('content', '')) for msg in data)
                except json.JSONDecodeError as e:
                    print(f"Warning: Invalid JSON at line {line_num}: {e}")
                    continue
    except IOError as e:
        print(f"Error reading file: {e}")
        return None
    
    # Calculate statistics
    file_size_kb = os.path.getsize(file_path) / 1024
    turns = Counter([len(conv) for conv in conversations])
    avg_chars_per_message = total_chars / total_messages if total_messages > 0 else 0
    
    # Prepare results
    stats = {
        'num_conversations': len(conversations),
        'total_messages': total_messages,
        'total_characters': total_chars,
        'avg_chars_per_message': avg_chars_per_message,
        'file_size_kb': file_size_kb,
        'turns_distribution': dict(turns),
        'file_path': file_path,
    }
    
    return stats, conversations


def print_statistics(stats, sample_count=3):
    """
    Print formatted statistics report.
    
    Args:
        stats: Statistics dictionary from analyze_safety_data()
        sample_count: Number of sample conversations to show
    """
    
    if stats is None:
        return
    
    print("\n" + "="*70)
    print("Safety Data Analysis Report")
    print("="*70)
    
    print(f"\nDataset Statistics:")
    print(f"  Total conversations: {stats['num_conversations']}")
    print(f"  Total messages: {stats['total_messages']}")
    print(f"  Total characters: {stats['total_characters']:,}")
    print(f"  Average characters per message: {stats['avg_chars_per_message']:.1f}")
    print(f"  File size: {stats['file_size_kb']:.1f} KB")
    
    print(f"\nConversation Turn Distribution:")
    for num_turns in sorted(stats['turns_distribution'].keys()):
        count = stats['turns_distribution'][num_turns]
        print(f"  {num_turns}-turn conversations: {count}")
    
    print(f"\nData Location:")
    print(f"  {stats['file_path']}")
    
    print("\n" + "="*70)


def print_samples(conversations, num_samples=2):
    """
    Print sample conversations to verify quality.
    
    Args:
        conversations: List of conversation data
        num_samples: Number of samples to display
    """
    
    if not conversations or num_samples <= 0:
        return
    
    import random
    num_samples = min(num_samples, len(conversations))
    
    print(f"\nSample Conversations (showing {num_samples} random examples):")
    print("="*70)
    
    sample_indices = random.sample(range(len(conversations)), num_samples)
    
    for sample_idx, idx in enumerate(sample_indices, 1):
        conversation = conversations[idx]
        print(f"\n--- Sample {sample_idx} ---")
        for msg in conversation:
            role = msg['role'].upper()
            content = msg['content']
            # Truncate long content for display
            if len(content) > 150:
                content = content[:150] + "..."
            print(f"[{role}]: {content}")
        print()


if __name__ == "__main__":
    # Analyze the safety data
    result = analyze_safety_data()
    
    if result is None:
        exit(1)
    
    stats, conversations = result
    
    # Print statistics report
    print_statistics(stats)
    
    # Print sample conversations
    print_samples(conversations, num_samples=2)
    
    print("\nâœ… Analysis complete!")

